"""
SLM Model Setup Script
Downloads and configures Small Language Models for local inference.

Architecture Overview:
=====================
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MAIN BRAIN (LLM)                        â”‚
â”‚              Llama 3.2 / GPT-4 / Claude                      â”‚
â”‚    Handles: Complex reasoning, orchestration, synthesis      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Intent SLM     â”‚  â”‚  Entity SLM     â”‚  â”‚  Compliance SLM â”‚
â”‚  (sklearn)      â”‚  â”‚  (sklearn)      â”‚  â”‚  (sklearn)      â”‚
â”‚  < 10ms         â”‚  â”‚  < 10ms         â”‚  â”‚  < 10ms         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SLM Types:
=========
1. sklearn (Recommended)
   - TF-IDF + Naive Bayes classifier
   - Trained on YOUR company data
   - No download needed, just train!
   - Inference: < 10ms

2. Ollama Small Models (Optional)
   - phi3:mini (2.7B params, 1.6GB)
   - tinyllama (1.1B params, 638MB)
   - For more complex local generation

3. Sentence Transformers (Optional)
   - For semantic similarity/matching
   - all-MiniLM-L6-v2 (22M params, 80MB)
"""

import subprocess
import sys
import os
from pathlib import Path


def check_ollama():
    """Check if Ollama is installed and running."""
    try:
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode == 0:
            print("âœ… Ollama is installed and running")
            print("\nCurrently installed models:")
            print(result.stdout)
            return True
        else:
            print("âŒ Ollama is not running")
            return False
    except FileNotFoundError:
        print("âŒ Ollama is not installed")
        print("   Install from: https://ollama.ai")
        return False
    except Exception as e:
        print(f"âŒ Error checking Ollama: {e}")
        return False


def download_ollama_slm(model_name: str):
    """Download an SLM via Ollama."""
    print(f"\nğŸ“¥ Downloading {model_name}...")
    try:
        result = subprocess.run(
            ["ollama", "pull", model_name],
            capture_output=False,  # Show progress
            timeout=600  # 10 minute timeout
        )
        if result.returncode == 0:
            print(f"âœ… {model_name} downloaded successfully")
            return True
        else:
            print(f"âŒ Failed to download {model_name}")
            return False
    except Exception as e:
        print(f"âŒ Error downloading {model_name}: {e}")
        return False


def setup_sklearn_slm():
    """Setup sklearn for SLM classification (recommended)."""
    print("\nğŸ“¦ Setting up sklearn for SLM classification...")
    
    try:
        import sklearn
        print(f"âœ… sklearn is installed (version {sklearn.__version__})")
        return True
    except ImportError:
        print("   Installing sklearn...")
        subprocess.run([sys.executable, "-m", "pip", "install", "scikit-learn"], check=True)
        print("âœ… sklearn installed successfully")
        return True


def setup_sentence_transformers():
    """Setup sentence transformers for semantic matching (optional)."""
    print("\nğŸ“¦ Setting up sentence transformers...")
    
    try:
        from sentence_transformers import SentenceTransformer
        print("âœ… sentence-transformers is installed")
        
        # Download a small model
        print("   Loading all-MiniLM-L6-v2 model...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… all-MiniLM-L6-v2 loaded (22M params, very fast)")
        return True
    except ImportError:
        print("   sentence-transformers not installed")
        print("   Run: pip install sentence-transformers")
        return False
    except Exception as e:
        print(f"âš ï¸  Error setting up sentence transformers: {e}")
        return False


def create_model_directory():
    """Create directory for trained SLM models."""
    model_dir = Path("models/slm")
    model_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ… Model directory created: {model_dir.absolute()}")
    return model_dir


def print_architecture():
    """Print the LLM + SLM architecture."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           JD JONES RAG - LLM + SLM ARCHITECTURE                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  â”‚                    MAIN BRAIN (LLM)                      â”‚    â•‘
â•‘  â”‚                     Llama 3.2 via Ollama                 â”‚    â•‘
â•‘  â”‚                                                          â”‚    â•‘
â•‘  â”‚  â€¢ Complex multi-step reasoning                          â”‚    â•‘
â•‘  â”‚  â€¢ Query orchestration                                   â”‚    â•‘
â•‘  â”‚  â€¢ Response synthesis                                    â”‚    â•‘
â•‘  â”‚  â€¢ Tool selection & execution                            â”‚    â•‘
â•‘  â”‚  â€¢ Latency: 500ms - 2s                                   â”‚    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â•‘
â•‘                           â”‚                                      â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â•‘
â•‘            â”‚              â”‚              â”‚                       â•‘
â•‘            â–¼              â–¼              â–¼                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â•‘
â•‘  â”‚ Intent SLM   â”‚ â”‚ Entity SLM   â”‚ â”‚ Matcher SLM  â”‚              â•‘
â•‘  â”‚ (sklearn)    â”‚ â”‚ (sklearn)    â”‚ â”‚ (sklearn)    â”‚              â•‘
â•‘  â”‚              â”‚ â”‚              â”‚ â”‚              â”‚              â•‘
â•‘  â”‚ â€¢ Classify   â”‚ â”‚ â€¢ Extract    â”‚ â”‚ â€¢ Product    â”‚              â•‘
â•‘  â”‚   intent     â”‚ â”‚   products   â”‚ â”‚   matching   â”‚              â•‘
â•‘  â”‚ â€¢ < 10ms     â”‚ â”‚ â€¢ < 10ms     â”‚ â”‚ â€¢ < 20ms     â”‚              â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â•‘
â•‘                                                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  WORKFLOW:                                                       â•‘
â•‘  1. Query â†’ SLM classifies intent (< 10ms)                       â•‘
â•‘  2. SLM extracts entities (product codes, specs) (< 10ms)        â•‘
â•‘  3. IF simple query: SLM handles directly                        â•‘
â•‘  4. IF complex: Escalate to LLM main brain                       â•‘
â•‘  5. LLM orchestrates tools, reasons, synthesizes                 â•‘
â•‘                                                                  â•‘
â•‘  BENEFITS:                                                       â•‘
â•‘  â€¢ 70-80% queries handled by SLM (< 50ms)                        â•‘
â•‘  â€¢ LLM only used for complex reasoning                           â•‘
â•‘  â€¢ SLMs trained on YOUR company data                             â•‘
â•‘  â€¢ Privacy-preserving (all local)                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


def print_next_steps():
    """Print next steps for training SLMs."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         NEXT STEPS                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  1. TRAIN SLMs ON YOUR DATA (API Endpoint):                      â•‘
â•‘     POST /agentic/slm/train                                      â•‘
â•‘     {                                                            â•‘
â•‘       "slm_type": "intent_classifier",                           â•‘
â•‘       "training_method": "sklearn",                              â•‘
â•‘       "num_examples": 100                                        â•‘
â•‘     }                                                            â•‘
â•‘                                                                  â•‘
â•‘  2. TEST SLM INFERENCE:                                          â•‘
â•‘     POST /agentic/slm/predict                                    â•‘
â•‘     {                                                            â•‘
â•‘       "slm_type": "intent_classifier",                           â•‘
â•‘       "text": "What is the temperature rating of NA 701?"        â•‘
â•‘     }                                                            â•‘
â•‘                                                                  â•‘
â•‘  3. VIEW SLM ARCHITECTURE:                                       â•‘
â•‘     GET /agentic/slm/architecture                                â•‘
â•‘                                                                  â•‘
â•‘  4. (OPTIONAL) DOWNLOAD ADDITIONAL OLLAMA MODELS:                â•‘
â•‘     ollama pull phi3:mini      # 1.6 GB                          â•‘
â•‘     ollama pull tinyllama      # 638 MB                          â•‘
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


def main():
    """Main setup function."""
    print("\n" + "="*60)
    print("       JD JONES RAG - SLM SETUP SCRIPT")
    print("="*60)
    
    # Print architecture overview
    print_architecture()
    
    # Check Ollama
    check_ollama()
    
    # Setup sklearn (recommended for SLM classification)
    setup_sklearn_slm()
    
    # Create model directory
    create_model_directory()
    
    # Optional: Setup sentence transformers
    print("\n" + "-"*60)
    print("Optional Components:")
    print("-"*60)
    
    setup_sentence_transformers()
    
    # Print next steps
    print_next_steps()
    
    print("\nâœ… SLM setup complete!")
    print("\nğŸ“ Summary:")
    print("   â€¢ You have Llama 3.2 as your MAIN BRAIN (LLM)")
    print("   â€¢ SLMs will be sklearn models trained on your data")
    print("   â€¢ Train SLMs via the API endpoints")
    print("   â€¢ No additional downloads required!")


if __name__ == "__main__":
    main()
